{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor([\n",
    "[\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "],\n",
    "[\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "]\n",
    "])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1].shape, X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = X[-1].repeat(3, 1, 1)\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2, 2])\n",
      "torch.Size([3, 4, 2])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(torch.cat([context, context], i).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 1, 2],\n",
       "         [3, 4, 3, 4]],\n",
       "\n",
       "        [[1, 2, 1, 2],\n",
       "         [3, 4, 3, 4]],\n",
       "\n",
       "        [[1, 2, 1, 2],\n",
       "         [3, 4, 3, 4]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_steps, batch_size, num_hiddens\n",
    "# 在 2 号维度上拼接，扩展每个矩阵的列, 扩展了输入的样本的每个时间步上的值的向量长度\n",
    "torch.cat([context, context], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "1, 2\n",
    "1, 2\n",
    "\n",
    "3, 4\n",
    "3, 4\n",
    "\n",
    "# batch_size, num_keys, key_size\n",
    "K = torch.tensor([\n",
    "    [[1, 2], [1, 2]],\n",
    "    [[3, 4], [3, 4]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3,  6],\n",
       "         [ 7, 14]],\n",
       "\n",
       "        [[ 9, 12],\n",
       "         [21, 28]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(W, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size, num_queries, num_hiddens\n",
    "# batch_size, num_keys_values, num_hiddens\n",
    "# ==>\n",
    "# batch_size, num_queries, 1, num_hiddens\n",
    "# batch_size, 1, num_keys_values, num_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_queries = 2\n",
    "num_hiddens = 5\n",
    "num_keys_values = 3\n",
    "\n",
    "queries = torch.rand(size=(batch_size, num_queries, num_hiddens))\n",
    "keys = torch.rand(size=(batch_size, num_keys_values, num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 5]), torch.Size([1, 3, 5]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.shape, keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 1, 5]), torch.Size([1, 1, 3, 5]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于扩展成这样的维度后\n",
    "# 广播的运行机制是\n",
    "# --------------------\n",
    "# 比如在 1 号维度，Y 的维度 < X 的维度\n",
    "# 这时候就要让维度值小的 扩展成 维度值高的\n",
    "# 所以在 1 号维度上 Y 向 X 看起 ==> 扩展方法是把更低维度的 2 号和 3 号上的内容复制多次堆叠在 1 号维度上\n",
    "# --------------------\n",
    "# 再比如 在 2 号维度上 X 的维度值 < Y 的维度值\n",
    "# 因此扩展 X 的 2 号维度数值\n",
    "# 扩展 2 号维度的数值，就要把比 2 号维度更低维度的所有维度的内容进行复制后堆叠在 2 号维度上\n",
    "# 在这里比 2 号维度低的维度只有 3 号维度，因此把一个 num_hiddens 长的向量复制 num_keys_values 次堆叠在 2 号维度上\n",
    "\n",
    "# 在三位世界中，第三个维度的长度为 1 ，那说明这个空间上的内容完全可以使用 2 维世界来承载\n",
    "X = queries.unsqueeze(2)  # batch_size, num_queries,      1,             num_hiddens\n",
    "Y = keys.unsqueeze(1)  # batch_size,         1,        num_keys_values,  num_hiddens\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = X + Y  # 这样就实现了每一个查询在所有的 keys 上做加法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.7006, 1.5571, 0.4660, 0.6582, 0.8745],\n",
       "         [1.0644, 1.5856, 0.7767, 1.3422, 0.9221],\n",
       "         [1.3725, 1.6271, 0.5387, 0.4978, 0.6640]],\n",
       "\n",
       "        [[1.9832, 1.4424, 0.7791, 0.2784, 0.9185],\n",
       "         [1.3470, 1.4709, 1.0898, 0.9624, 0.9661],\n",
       "         [1.6551, 1.5123, 0.8518, 0.1180, 0.7079]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86bb26bcf3701c754d5fd40db657c5b7e15a074c1099b32f8fc32052c18ad091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
